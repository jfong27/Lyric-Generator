{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unigram Markov Chain Model\n",
    "\n",
    "You will build a Markov chain for the artist whose lyrics you scraped in Part 1. To do this, you have to go through the lyrics and learn the word transitions for that artist. You will store this information in a dict called `chain`, which maps each word to a list of words that appear after it in the training data. So for example, one entry of this dict might be\n",
    "\n",
    "```\n",
    "chain = {\n",
    "    \"it\": [\"is\", \"runs\", \"is\", \"is\", \"was\", \"is\", \"was\"],\n",
    "    ...\n",
    "}\n",
    "```\n",
    "\n",
    "You should include a few additional states, besides words, in your Markov chain. You should have `\"<START>\"` and `\"<END>\"` states so that we can keep track of what words songs are likely to begin and end on. You should also include a state called `\"<N>\"` to denote line breaks so that you can keep track of where lines begin and end. \n",
    "\n",
    "So if the song starts with the line \"Is this the real life?\" and ends with the line \"Nothing really matters to me.\", you would have a dictionary that looks like\n",
    "```\n",
    "chain = {\n",
    "    \"<START>\": [\"Is\", ...],\n",
    "    \"Is\": [\"this\", ...],\n",
    "    \"this\": [\"the\", ...],\n",
    "    \"the\": [\"real\", ...],\n",
    "    \"real\": [\"life?\", ...],\n",
    "    \"life?\": [\"<N>\", ...],\n",
    "    \"<N>\": [\"Nothing\", ...],\n",
    "    \"Nothing\": [\"really\", ...],\n",
    "    \"really\": [\"matters\", ...],\n",
    "    \"matters\": [\"to\", ...],\n",
    "    \"to\": [\"me\", ...],\n",
    "    \"me.\": [\"<END>\", ...],\n",
    "    ...\n",
    "}\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train_markov_chain(lyrics):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "      - lyrics: a list of strings, where each string represents\n",
    "                the lyrics of one song by an artist.\n",
    "    \n",
    "    Returns:\n",
    "      A dict that maps a single word (\"unigram\") to a list of\n",
    "      words that follow that word, representing the Markov\n",
    "      chain trained on the lyrics.\n",
    "    \"\"\"\n",
    "    chain = {\"<START>\": [],\n",
    "             \"<N>\": []}\n",
    "\n",
    "    for lyric in lyrics:\n",
    "        words = lyric.split()\n",
    "        chain[\"<START>\"].append(words[0])\n",
    "        for i in range(0, len(words)-1):\n",
    "            word = words[i]\n",
    "            if word in chain:\n",
    "                chain[word].append(words[i+1])\n",
    "            else:\n",
    "                chain[word] = [words[i+1]]\n",
    "        last_word = words[-1]\n",
    "        if last_word in chain:\n",
    "            chain[last_word].append(\"<END>\")\n",
    "        else:\n",
    "            chain[last_word] = [\"<END>\"]\n",
    "    \n",
    "    return chain\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A', 'Uh,', 'A', 'I', \"I've\", 'I', \"That's\", 'Round', 'Too', 'Set', 'My', 'And', 'Double', 'Hand', 'My', 'Pool', 'A', 'Taxi', 'Yeah,', 'Bad']\n",
      "['Excuse', 'In', 'My', 'when', '(Ooh,', \"I've\", '(You', \"I've\", 'Do', 'Do', \"'Cause\", \"'Cause\", 'Enough', 'Got', 'Since', \"That's\", 'Got', \"Thinkin'\", '(Ooh,', \"I've\"]\n"
     ]
    }
   ],
   "source": [
    "# Load the pickled lyrics object that you created in Part 1.\n",
    "import pickle\n",
    "lyrics = pickle.load(open(\"lyrics.pkl\", \"rb\"))\n",
    "\n",
    "# Call the function you wrote above.\n",
    "chain = train_markov_chain(lyrics)\n",
    "# What words tend to start a song (i.e., what words follow the <START> tag?)\n",
    "print(chain[\"<START>\"][:20])\n",
    "\n",
    "# What words tend to begin a line (i.e., what words follow the line break tag?)\n",
    "print(chain[\"<N>\"][:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's generate new lyrics using the Markov chain you constructed above. To do this, we'll begin at the `\"<START>\"` state and randomly sample a word from the list of first words. Then, we'll randomly sample each next word from the list of words that appeared after the current word in the training data. We will continue this until we reach the `\"<END>\"` state. This will give us the complete lyrics of a randomly generated song!\n",
    "\n",
    "You may find the `random.choice()` function helpful for this question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def generate_new_lyrics(chain):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "      - chain: a dict representing the Markov chain,\n",
    "               such as one generated by generate_new_lyrics()\n",
    "    \n",
    "    Returns:\n",
    "      A string representing the randomly generated song.\n",
    "    \"\"\"\n",
    "    \n",
    "    # a list for storing the generated words\n",
    "    words = []\n",
    "    # generate the first word\n",
    "    curr_word = random.choice(chain[\"<START>\"])\n",
    "    words.append(curr_word)\n",
    "    while(curr_word != \"<END>\"):\n",
    "        next_word = random.choice(chain[curr_word])\n",
    "        words.append(next_word)\n",
    "        curr_word = next_word\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    \n",
    "    # join the words together into a string with line breaks\n",
    "    lyrics = \" \".join(words[:-1])\n",
    "    return \"\\n\".join(lyrics.split(\"<N>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wiseman closed his ice blue \n",
      " Our daughters and my mind boy you were better than me take no place \n",
      " African girl found you \n",
      " So take it faded on a see what we make a cult \n",
      " My Amex and my voice \n",
      " No more time \n",
      " Niggas hustle every day bruh \n",
      " yes we could think twice \n",
      " [Hook] \n",
      " but I'm fuckin' with your husband? \n",
      " How come by the scream mask for dollar Delta gift cards \n",
      " Far's too late night shift \n",
      " With no man don't like in the mind) \n",
      " Is that I \n",
      " But you weren't either \n",
      " A sweet life in these ladies show him love \n",
      " ohhh \n",
      " I could see myself at home \n",
      " You found it Sweet King Martin, sweet life \n",
      " The maids come the crows \n",
      " Parents ain't free and white lines \n",
      " How much \n",
      " No you up \n",
      " To hold her term papers in the streets now \n",
      " Stayin' with nothing \n",
      " All my gifts for the glass, seen you thought you now, when I'm faithful \n",
      " Whip ain't gotta know \n",
      " I don't clock \n",
      " You look like Chanel \n",
      " Underneath our slumber \n",
      " Oh, oh, oh \n",
      " It's like in your bitches, I'mma give me \n",
      " That's a job since 3 6, Pimp C \n",
      " Last thing won't lie if you slide on me to work in the blade and no choice \n",
      " Meet me \n",
      " So many bottles of you on the clouds \n",
      " Kick off like a job \n",
      " Talking to pay, but between happy, being bad dreams, Cleopatra The entire Earth and my forehead \n",
      " At the air \n",
      " A new brakes \n",
      " (Ball so far ahead (ahead)? \n",
      " You my place to me momma raised me, pardon my badness \n",
      " It went to swim good \n",
      " You look out a [dick] in line \n",
      " Disillusioned, ooh \n",
      " that was in her at the pyramid tonight \n",
      " Don't believe there's trees burn \n",
      " I rose my nuts hang with pain Pretty fucking \n",
      " Swim inside the future first memory? The son who needs you to live, too much \n",
      " What is not sorry \n",
      " Getting married in the tip now \n",
      " That's just wanna keep the life \n",
      " I'm down there are lifting off the truth about forever (ooh, ooh) No, not too \n",
      " Wrong side with cracky Hittin' stones in my Daniel \n",
      " On me none \n",
      " (We were so far ahead? (Ahead) \n",
      " 'Cause I've had an American wedding \n",
      " Planning a funeral \n",
      " (Be Ready, Be Ready) Bridge A-Yo \n",
      " that ledge, she met you now I thought you on me I thought I just to, get you were things that were there, right now you \n",
      " But I like this life) \n",
      " Everyday counts like a republic, that mean my sofa yeah \n",
      " They thought \n",
      " Hit the things that I said, \"What if we did it\n"
     ]
    }
   ],
   "source": [
    "print(generate_new_lyrics(chain))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grader's Comments\n",
    "\n",
    "- \n",
    "- \n",
    "\n",
    "[This question is worth 20 points.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This cell should only be modified only by a grader.\n",
    "scores = [None]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
